{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cosmaadrian/ml-environment/blob/master/DSM_Lab_FixMatch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIfzH1M7IZMM"
      },
      "source": [
        "# Semi-Supervised Learning with FixMatch\n",
        "\n",
        "In this lab, we will explore the implementation of FixMatch, a method for performing semi-supervised learning.\n",
        "\n",
        "We will perform our training on a fraction of CIFAR10, a dataset of natural images\n",
        "\n",
        "You can find the original paper here: FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence (https://arxiv.org/abs/2001.07685)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxxtw2ThIrZJ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import RandomSampler, SequentialSampler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVVPuvbzIteq"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train_epoch(model, dataloader, device, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "\n",
        "    total_train_loss = 0.0\n",
        "    dataset_size = 0\n",
        "\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader), colour='cyan', file=sys.stdout)\n",
        "\n",
        "    for step, (images, labels) in bar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(images)\n",
        "        loss = criterion(pred, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "\n",
        "        epoch_loss = np.round(total_train_loss / dataset_size, 2)\n",
        "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss)\n",
        "\n",
        "\n",
        "    return epoch_loss\n",
        "\n",
        "def valid_epoch(model, dataloader, device, criterion, epoch):\n",
        "    model.eval()\n",
        "\n",
        "    total_val_loss = 0.0\n",
        "    dataset_size = 0\n",
        "\n",
        "    correct = 0\n",
        "\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader), colour='cyan', file=sys.stdout)\n",
        "    for step, (images, labels) in bar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "\n",
        "        pred = model(images)\n",
        "        loss = criterion(pred, labels)\n",
        "\n",
        "        _, predicted = torch.max(pred, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        total_val_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "\n",
        "        epoch_loss = np.round(total_val_loss / dataset_size, 2)\n",
        "\n",
        "        accuracy = np.round(100 * correct / dataset_size, 2)\n",
        "\n",
        "        bar.set_postfix(Epoch=epoch, Valid_Acc=accuracy, Valid_Loss=epoch_loss)\n",
        "\n",
        "    return accuracy, epoch_loss\n",
        "\n",
        "def run_training(model, trainloader, testloader, criterion, optimizer, num_epochs):\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
        "\n",
        "    top_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        train_loss = train_epoch(model, trainloader, device, optimizer, criterion, epoch)\n",
        "        with torch.no_grad():\n",
        "            val_accuracy, val_loss = valid_epoch(model, testloader, device, criterion, epoch)\n",
        "            if val_accuracy > top_accuracy:\n",
        "                print(f\"Validation Accuracy Improved ({top_accuracy} ---> {val_accuracy})\")\n",
        "                top_accuracy = val_accuracy\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB2K6AkoIyLd",
        "outputId": "c6c89463-0fc4-4237-dc03-efb125ee27e5"
      },
      "outputs": [],
      "source": [
        "# Don't touch this for now.\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "cifar_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "cifar_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Let's just use 10% of the data to make it harder\n",
        "from collections import defaultdict\n",
        "indices_per_class = defaultdict(list)\n",
        "for i in range(len(cifar_trainset)):\n",
        "  _, class_label = cifar_trainset[i]\n",
        "  indices_per_class[class_label].append(i)\n",
        "\n",
        "labeled_indices = []\n",
        "unlabeled_indices = []\n",
        "for class_name, indices in indices_per_class.items():\n",
        "  labeled_indices.extend(indices[:int(0.1 * len(indices))]) # 10% labeled\n",
        "  unlabeled_indices.extend(indices[int(0.1 * len(indices)):]) # 90% unlabeled\n",
        "\n",
        "cifar_labeled_trainset = torch.utils.data.Subset(dataset = cifar_trainset, indices = labeled_indices)\n",
        "\n",
        "cifar_labeled_trainloader = DataLoader(cifar_labeled_trainset, batch_size=64, shuffle=True)\n",
        "cifar_testloader = DataLoader(cifar_testset, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n30DeNSgKQfu"
      },
      "source": [
        "# Baseline: Training just with the supervised data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfMgwZewJddY",
        "outputId": "f7499174-b99d-432a-d6f2-16e4ab1214e6"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained = False) # let's initialize a ResNet18 from scratch and pretrain it ourselves\n",
        "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=10, bias=True)\n",
        "\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Adam is an improved gradient descent algorithm\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC230FhoJlgF",
        "outputId": "7269423e-26fd-42d3-bb41-adea42033fd1"
      },
      "outputs": [],
      "source": [
        "run_training(model, cifar_labeled_trainloader, cifar_testloader, criterion = criterion, optimizer = optimizer, num_epochs = epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU9jGYtwKJfV"
      },
      "source": [
        "## Results suck. Let's make them better.\n",
        "\n",
        "First, let's define a set of weak and strong augmentations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgF5v90TJtzm"
      },
      "outputs": [],
      "source": [
        "weak_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomCrop(32, padding=int(32*0.125)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Strong augmentations (additional color jitter & grayscale)\n",
        "strong_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomCrop(32, padding=int(32*0.125)),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "class TransformFixMatch(object):\n",
        "    def __init__(self, weak, strong):\n",
        "        self.weak = weak\n",
        "        self.strong = strong\n",
        "\n",
        "    def __call__(self, x):\n",
        "        weak = self.weak(x)\n",
        "        strong = self.strong(x)\n",
        "\n",
        "        return weak, strong\n",
        "\n",
        "class CIFAR10SSL(datasets.CIFAR10):\n",
        "    def __init__(self, root, indexs, train=True, transform=None, target_transform=None, download=False):\n",
        "        super().__init__(root, train=train, transform=transform, target_transform=target_transform, download=download)\n",
        "        if indexs is not None:\n",
        "            self.data = self.data[indexs]\n",
        "            self.targets = np.array(self.targets)[indexs]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiBDV-wfMaL5"
      },
      "outputs": [],
      "source": [
        "# Adding the new transforms\n",
        "cifar_labeled_trainset = CIFAR10SSL(root='./data', indexs = labeled_indices, train=True, transform = weak_transforms)\n",
        "cifar_unlabeled_trainset = CIFAR10SSL(root='./data', indexs = unlabeled_indices, train=True, transform=TransformFixMatch(weak = weak_transforms, strong = strong_transforms))\n",
        "cifar_testset = datasets.CIFAR10(root='./data', train=False, transform = val_transforms, download=False)\n",
        "\n",
        "# One training batch contains 1/8 labeled data and 7/8 unlabeled data.\n",
        "cifar_labeled_trainloader = DataLoader(cifar_labeled_trainset, batch_size=64, sampler = RandomSampler(cifar_labeled_trainset))\n",
        "cifar_unlabeled_trainloader = DataLoader(cifar_unlabeled_trainset, batch_size=7 * 64, sampler = RandomSampler(cifar_unlabeled_trainset))\n",
        "\n",
        "# Test set is all labeled\n",
        "cifar_testloader = DataLoader(cifar_testset, batch_size=64, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ON9y5_JJOf4e"
      },
      "outputs": [],
      "source": [
        "def train_fixmatch_epoch(model, labeled_dataloader, unlabeled_dataloader, device, optimizer, epoch):\n",
        "    criterion_labeled = nn.CrossEntropyLoss()\n",
        "    criterion_unlabeled = nn.CrossEntropyLoss(reduction='none')  # Per-example loss\n",
        "\n",
        "    threshold = 0.90  # Pseudo-label confidence threshold\n",
        "\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    bar = tqdm(enumerate(unlabeled_dataloader), total=len(unlabeled_dataloader), colour='cyan', file=sys.stdout)\n",
        "    bar.set_description(f\"Epoch {epoch}\")\n",
        "\n",
        "    labeled_iterator = iter(labeled_dataloader)\n",
        "\n",
        "    for step, (unlabeled_images, _) in bar:\n",
        "        unlabeled_images_weak, unlabeled_images_strong = unlabeled_images\n",
        "        unlabeled_images_weak = unlabeled_images_weak.to(device)\n",
        "        unlabeled_images_strong = unlabeled_images_strong.to(device)\n",
        "\n",
        "        # Get next batch of labeled data (handle StopIteration)\n",
        "        try:\n",
        "            labeled_images, labels = next(labeled_iterator)\n",
        "        except StopIteration:\n",
        "            labeled_iterator = iter(labeled_dataloader)\n",
        "            labeled_images, labels = next(labeled_iterator)\n",
        "\n",
        "        labeled_images = labeled_images.to(device)\n",
        "        labels = labels.to(device).long()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Compute predictions on labeled data\n",
        "        pred_labeled = model(labeled_images)\n",
        "        loss_labeled = criterion_labeled(pred_labeled, labels)\n",
        "\n",
        "        # Compute pseudo-labels for weakly augmented images\n",
        "        with torch.no_grad():\n",
        "            pred_weak = model(unlabeled_images_weak)\n",
        "            pred_weak_confidence = torch.nn.functional.softmax(pred_weak, dim=-1)\n",
        "            max_values, max_indices = torch.max(pred_weak_confidence, dim=-1)\n",
        "            max_indices = max_indices.to(device).long()\n",
        "\n",
        "            # Create FixMatch mask (ignore low-confidence predictions)\n",
        "            fixmatch_mask = (max_values > threshold).float()\n",
        "\n",
        "        # TODO other things to try out\n",
        "        # add mixup between labeled data and unlabeled data\n",
        "        # (interpolate labeled images with strongly augmented unlabeled images and between corresponding true labels and pseudo-labels)\n",
        "        # mixup: BEYOND EMPIRICAL RISK MINIMIZATION https://arxiv.org/pdf/1710.09412\n",
        "\n",
        "        # TODO (more complicated)\n",
        "        # some pseudo-labels might be wrong and stay wrong throughout training\n",
        "        # maybe figure out which ones are wrong by looking at training dynamics\n",
        "        # Identifying Mislabeled Data using the Area Under the Margin Ranking https://arxiv.org/pdf/2001.10528\n",
        "        # MarginMatch: Improving Semi-Supervised Learning with Pseudo-Margins https://arxiv.org/pdf/2308.09037\n",
        "\n",
        "        pred_strong = model(unlabeled_images_strong)\n",
        "\n",
        "        # loss for labeled images (nothing special, crossentropy between true labels and preds)\n",
        "        loss_labeled = criterion_labeled(pred_labeled, labels)\n",
        "\n",
        "        # loss for unlabeled: crossentropy between high-confidence pseudo-labels on weak augmentations and preds on strong augmentations\n",
        "        # fixmatch_mask filters out unconfident pseudo-labels\n",
        "        loss_consistency = criterion_unlabeled(pred_strong, max_indices) * fixmatch_mask\n",
        "        loss_consistency = loss_consistency.mean()\n",
        "\n",
        "        # Total loss (labeled + consistency)\n",
        "        loss = loss_labeled + loss_consistency\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        bar.set_postfix(\n",
        "            Epoch=epoch,\n",
        "            LabeledLoss=loss_labeled.item(),\n",
        "            ConsistencyLoss=loss_consistency.item(),\n",
        "            FractionMasked=(1 - fixmatch_mask.float().mean().clamp(min=1e-6)).item()\n",
        "        )\n",
        "\n",
        "    return epoch_loss / len(unlabeled_dataloader)\n",
        "\n",
        "def run_training_fixmatch(model, labeled_trainloader, unlabeled_trainloader, testloader, optimizer, num_epochs):\n",
        "    print(f\"[INFO] Using device: {device}\")\n",
        "\n",
        "    top_accuracy = 0.0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train_fixmatch_epoch(model, labeled_trainloader, unlabeled_trainloader, device, optimizer, epoch)\n",
        "        print(f\"Epoch {epoch} Loss: {train_loss:.2f}\")\n",
        "\n",
        "        # Validate the model after each epoch\n",
        "        with torch.no_grad():\n",
        "            val_accuracy, val_loss = valid_epoch(model, testloader, device, criterion, epoch)\n",
        "            print(f\"Validation Accuracy: {val_accuracy:.2f} | Validation Loss: {val_loss:.2f}\")\n",
        "    \n",
        "            # Save best model based on validation accuracy\n",
        "            if val_accuracy > top_accuracy:\n",
        "                print(f\"Validation Accuracy Improved ({top_accuracy:.2f} ---> {val_accuracy:.2f})\")\n",
        "                top_accuracy = val_accuracy\n",
        "\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBHO5fQgUyYA",
        "outputId": "166b9420-9198-4451-bc27-41500c5dd4cb"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 40\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=False)  # No pretraining\n",
        "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=10, bias=True)\n",
        "model.to(device)\n",
        "\n",
        "# Adam is an improved gradient descent algorithm\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oFgPflpLVV40",
        "outputId": "f638a715-f1d2-4f54-9681-1206d4345630"
      },
      "outputs": [],
      "source": [
        "run_training_fixmatch(\n",
        "    model,\n",
        "    labeled_trainloader=cifar_labeled_trainloader,\n",
        "    unlabeled_trainloader=cifar_unlabeled_trainloader,\n",
        "    testloader=cifar_testloader,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=epochs\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNe7vTnb5NU5eHd9T4icvAm",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
