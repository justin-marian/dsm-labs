{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cosmaadrian/ml-environment/blob/master/DSM_SimCLR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mqen6PAcwfZU"
      },
      "source": [
        "# Self-supervised contrastive learning with SimCLR\n",
        "\n",
        "In this lab, we will explore the implementation of SimCLR, a method for self-supervised pretraining of networks.\n",
        "\n",
        "We will perform our pretraining on CIFAR10, a dataset of natural images, and then fine tune our network on SVHN, a dataset of pictures of house numbers.\n",
        "\n",
        "You can find the original paper here: A Simple Framework for Contrastive Learning of Visual Representations (https://arxiv.org/abs/2002.05709)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7As4KHUyINN"
      },
      "source": [
        "First off, lets define the training and validation loops for normal, supervised classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCO34aSSxCC9"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhvT4M7KxGwn"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train_epoch(model, dataloader, device, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "\n",
        "    total_train_loss = 0.0\n",
        "    dataset_size = 0\n",
        "\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader), colour='cyan', file=sys.stdout)\n",
        "    for step, (images, labels) in bar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(images)\n",
        "        loss = criterion(pred, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "\n",
        "        epoch_loss = np.round(total_train_loss / dataset_size, 2)\n",
        "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss)\n",
        "\n",
        "\n",
        "    return epoch_loss\n",
        "\n",
        "def valid_epoch(model, dataloader, device, criterion, epoch):\n",
        "    model.eval()\n",
        "\n",
        "    total_val_loss = 0.0\n",
        "    dataset_size = 0\n",
        "\n",
        "    correct = 0\n",
        "\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader), colour='cyan', file=sys.stdout)\n",
        "    for step, (images, labels) in bar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "\n",
        "        pred = model(images)\n",
        "        loss = criterion(pred, labels)\n",
        "\n",
        "        _, predicted = torch.max(pred, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        total_val_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "\n",
        "        epoch_loss = np.round(total_val_loss / dataset_size, 2)\n",
        "\n",
        "        accuracy = np.round(100 * correct / dataset_size, 2)\n",
        "\n",
        "        bar.set_postfix(Epoch=epoch, Valid_Acc=accuracy, Valid_Loss=epoch_loss)\n",
        "\n",
        "    return accuracy, epoch_loss\n",
        "\n",
        "def run_training(model, trainloader, testloader, criterion, optimizer, num_epochs):\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
        "\n",
        "    top_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        train_loss = train_epoch(model, trainloader, device, optimizer, criterion, epoch)\n",
        "        with torch.no_grad():\n",
        "            val_accuracy, val_loss = valid_epoch(model, testloader, device, criterion, epoch)\n",
        "            if val_accuracy > top_accuracy:\n",
        "                print(f\"Validation Accuracy Improved ({top_accuracy} ---> {val_accuracy})\")\n",
        "                top_accuracy = val_accuracy\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVFeXDa9ykCO",
        "outputId": "e0b48c84-7942-4523-ccc1-9ea2c312efc3"
      },
      "outputs": [],
      "source": [
        "# TODO - Add more transforms that act as image augmentations\n",
        "# Remember that Self-Supervised methods benefit greatly from \"heavier\" data augmentations\n",
        "# Checkout https://pytorch.org/vision/0.9/transforms.html\n",
        "# Or search on google for a SimCLR implementation and copy their transforms from there\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),  # Random rotation\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "cifar_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "cifar_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "# Define SVHN dataset (the final, downstream one)\n",
        "svhn_trainset = datasets.SVHN(root='./data', split='train', download=True, transform=transform)\n",
        "svhn_testset = datasets.SVHN(root='./data', split='test', download=True, transform=transform)\n",
        "\n",
        "# Let's just use 10% of the data to make it harder\n",
        "# TODO test what happens with even fewer data, like 1%, 5% etc.\n",
        "from collections import defaultdict\n",
        "indices_per_class = defaultdict(list)\n",
        "for i in range(len(svhn_trainset)):\n",
        "  _, class_label = svhn_trainset[i]\n",
        "  indices_per_class[class_label].append(i)\n",
        "\n",
        "final_indices = []\n",
        "for class_name, indices in indices_per_class.items():\n",
        "  sampled_indices = indices[:int(0.1 * len(indices))]\n",
        "  final_indices.extend(sampled_indices)\n",
        "\n",
        "svhn_trainset = torch.utils.data.Subset(dataset = svhn_trainset, indices = final_indices)\n",
        "\n",
        "svhn_trainloader = DataLoader(svhn_trainset, batch_size=256, shuffle=True)\n",
        "svhn_testloader = DataLoader(svhn_testset, batch_size=256, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "82SU5Ng43ImQ",
        "outputId": "18c6a4f3-887d-409c-b16e-2e5ba7a49818"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "cifar_trainloader = DataLoader(cifar_trainset, batch_size=256, shuffle=True)\n",
        "# get some random training images\n",
        "dataiter = iter(cifar_trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[:8]))\n",
        "print(' '.join('%8s' % classes[labels[j]] for j in range(8)))\n",
        "plt.show()\n",
        "\n",
        "print('SVHN')\n",
        "\n",
        "dataiter = iter(svhn_trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[:8]))\n",
        "print(' '.join('%8s' % labels[j].item() for j in range(8)))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-qckcFQzW3p"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 5\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained = False) # let's initialize a ResNet18 from scratch and pretrain it ourselves\n",
        "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=10, bias=True)\n",
        "\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# AdamW is an improved gradient descent algorithm\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52v2_R-B2FOB"
      },
      "source": [
        "### Baseline result: Training a ResNet-18 from scratch on SVHN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW4GFaIN0Vnf",
        "outputId": "e23bd446-d9e0-4907-bdff-60ca841b11c8"
      },
      "outputs": [],
      "source": [
        "run_training(model, svhn_trainloader, svhn_testloader, criterion = criterion, optimizer = optimizer, num_epochs = epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyoKP0Ue4Zkx"
      },
      "source": [
        "## Baseline SVHN result is ... okish?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoTLtOfz4gyy"
      },
      "source": [
        "Can we do better?\n",
        "\n",
        "YES!\n",
        "\n",
        "Let's pretrain on CIFAR10 using SimCLR. First, let's define the SimCLR loss (contrastive loss).\n",
        "\n",
        "Details are not important now. You can read the paper if you want to learn more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FR_7alS2O4k"
      },
      "outputs": [],
      "source": [
        "class SimCLRLoss(nn.Module):\n",
        "    def __init__(self, batch_size, temperature):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.temperature = temperature\n",
        "\n",
        "        self.mask = self.mask_correlated_samples(batch_size)\n",
        "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "        self.similarity_f = nn.CosineSimilarity(dim=2)\n",
        "\n",
        "    def mask_correlated_samples(self, batch_size):\n",
        "        N = 2 * batch_size\n",
        "        mask = torch.ones((N, N), dtype=bool)\n",
        "        mask = mask.fill_diagonal_(0)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            mask[i, batch_size + i] = 0\n",
        "            mask[batch_size + i, i] = 0\n",
        "        return mask\n",
        "\n",
        "    def forward(self, z_i, z_j):\n",
        "\n",
        "        N = 2 * self.batch_size\n",
        "\n",
        "        z = torch.cat((z_i, z_j), dim=0)\n",
        "\n",
        "        sim = self.similarity_f(z.unsqueeze(1), z.unsqueeze(0)) / self.temperature\n",
        "\n",
        "        sim_i_j = torch.diag(sim, self.batch_size)\n",
        "        sim_j_i = torch.diag(sim, -self.batch_size)\n",
        "\n",
        "        # We have 2N samples, but with Distributed training every GPU gets N examples too, resulting in: 2xNxN\n",
        "        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(N, 1)\n",
        "        negative_samples = sim[self.mask].reshape(N, -1)\n",
        "\n",
        "        #SIMCLR\n",
        "        labels = torch.from_numpy(np.array([0]*N)).reshape(-1).to(positive_samples.device).long() #.float()\n",
        "\n",
        "        logits = torch.cat((positive_samples, negative_samples), dim=1)\n",
        "        loss = self.criterion(logits, labels)\n",
        "        loss /= N\n",
        "\n",
        "        return loss\n",
        "\n",
        "# helper stuff\n",
        "def plot_features(model, dataloader, num_feats, batch_size):\n",
        "    preds = np.array([]).reshape((0,1))\n",
        "    gt = np.array([]).reshape((0,1))\n",
        "    feats = np.array([]).reshape((0,num_feats))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (x1,x2) in enumerate(dataloader):\n",
        "            x1 = x1.squeeze().to(device = device, dtype = torch.float)\n",
        "            out = model(x1)\n",
        "            out = out.cpu().data.numpy()\n",
        "            feats = np.append(feats, out, axis = 0)\n",
        "\n",
        "            if i == 100:\n",
        "              break\n",
        "\n",
        "    tsne = TSNE(n_components = 2, perplexity = 50, verbose = 2)\n",
        "    x_feats = tsne.fit_transform(feats)\n",
        "\n",
        "    plt.scatter(x_feats[:, 1], x_feats[:, 0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HrM_KDc5DSS"
      },
      "source": [
        "Custom model wrapper to have a projection head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFQfSTWL4-DO"
      },
      "outputs": [],
      "source": [
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "class ModelForPretraining(nn.Module):\n",
        "    def __init__(self, projector_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.pretrained = torchvision.models.resnet18(pretrained=False)\n",
        "\n",
        "        self.pretrained.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
        "        self.pretrained.maxpool = Identity()\n",
        "        self.pretrained.fc = Identity()\n",
        "\n",
        "        for p in self.pretrained.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "        # TODO probably needs some adjusting, maybe it's too small?\n",
        "        # TODO instead of a Linear layer, make it a MLP. Check the paper.\n",
        "        self.projector = nn.Sequential(\n",
        "                nn.Linear(512, 512),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(512, projector_size)\n",
        "            )\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.pretrained(x)\n",
        "        xp = self.projector(torch.squeeze(out))\n",
        "        return xp\n",
        "\n",
        "class ModelForFinetuning(nn.Module):\n",
        "    def __init__(self, pretrained_model, num_classes = 10, freeze_backbone = True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.premodel = pretrained_model\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Freeze the layers of the pretrained model\n",
        "\n",
        "        # TODO Optionally freeze model parameters if you have a good model and train only the last layer\n",
        "        if freeze_backbone:\n",
        "            for p in self.premodel.pretrained.parameters():\n",
        "                p.requires_grad = False  # Freeze ResNet backbone\n",
        "            for p in self.premodel.projector.parameters():\n",
        "                p.requires_grad = False  # Freeze projector head\n",
        "\n",
        "        # Fine-tune only the last layer\n",
        "        self.lastlayer = nn.Linear(512, self.num_classes)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.premodel.pretrained(x)\n",
        "        out = self.lastlayer(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxiKrg_w6XwN"
      },
      "source": [
        "# SimCLR training loop\n",
        "## Augment an image two ways and compute the contrastive loss with respect to the other images in the batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CinJxtmq8fmC"
      },
      "outputs": [],
      "source": [
        "class TwoViewsDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, source_dataset):\n",
        "    # WARNING !!!! This assumes the dataset outputs augmented images\n",
        "    self.source_dataset = source_dataset\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.source_dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # each time is a different augmentation of the same image\n",
        "    view1, _ = self.source_dataset[idx]\n",
        "    view2, _ = self.source_dataset[idx]\n",
        "\n",
        "    return view1, view2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqY0m1th6MhY",
        "outputId": "1b59e700-d158-4eff-dbce-9b921d9bbaa1"
      },
      "outputs": [],
      "source": [
        "cifar_trainloader = DataLoader(TwoViewsDataset(source_dataset = cifar_trainset), batch_size=128, shuffle=True, drop_last = True)\n",
        "cifar_testloader = DataLoader(TwoViewsDataset(source_dataset = cifar_testset), batch_size=128, shuffle=True, drop_last = True)\n",
        "\n",
        "epochs = 5\n",
        "temperature = 0.5\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "\n",
        "model_for_pretraining = ModelForPretraining(projector_size=256).to(device)\n",
        "criterion = SimCLRLoss(batch_size=batch_size, temperature=temperature)\n",
        "optimizer = optim.AdamW(model_for_pretraining.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch [{epoch+1}/{epochs}]\")\n",
        "    model_for_pretraining.train()\n",
        "    \n",
        "    train_loss_epoch = 0\n",
        "\n",
        "    for step, (x_i, x_j) in enumerate(tqdm(cifar_trainloader, total=len(cifar_trainloader))):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x_i, x_j = x_i.to(device).float(), x_j.to(device).float()\n",
        "\n",
        "        # Forward pass through encoder + projector\n",
        "        z_i = model_for_pretraining(x_i)\n",
        "        z_j = model_for_pretraining(x_j)\n",
        "\n",
        "        # Compute contrastive loss\n",
        "        loss = criterion(z_i, z_j)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_epoch += loss.item()\n",
        "\n",
        "        if step % 25 == 0:  # Print every 25 steps\n",
        "            print(f\"Step [{step}/{len(cifar_trainloader)}]  Train Loss: {round(loss.item(), 5)}\")\n",
        "\n",
        "    avg_train_loss = train_loss_epoch / len(cifar_trainloader)\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}]  Avg Train Loss: {round(avg_train_loss, 5)}\")\n",
        "\n",
        "    model_for_pretraining.eval()\n",
        "    val_loss_epoch = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for step, (x_i, x_j) in enumerate(tqdm(cifar_testloader, total=len(cifar_testloader))):\n",
        "            x_i, x_j = x_i.to(device).float(), x_j.to(device).float()\n",
        "\n",
        "            z_i = model_for_pretraining(x_i)\n",
        "            z_j = model_for_pretraining(x_j)\n",
        "\n",
        "            loss = criterion(z_i, z_j)\n",
        "            val_loss_epoch += loss.item()\n",
        "\n",
        "            if step % 25 == 0:\n",
        "                print(f\"Step [{step}/{len(cifar_testloader)}]  Val Loss: {round(loss.item(),5)}\")\n",
        "\n",
        "    avg_val_loss = val_loss_epoch / len(cifar_testloader)\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}]  Avg Val Loss: {round(avg_val_loss, 5)}\")\n",
        "\n",
        "    plot_features(model_for_pretraining.pretrained, cifar_testloader, 512, 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4UpGY5WHebC"
      },
      "source": [
        "## Model fine-tuning on 10% of SVHN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "Git-9vP3H2he",
        "outputId": "5242a91c-330a-4a4d-cb9f-e8bdcf2089a7"
      },
      "outputs": [],
      "source": [
        "downstream_model = ModelForFinetuning(pretrained_model = model_for_pretraining)\n",
        "downstream_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Adam is an improved gradient descent algorithm\n",
        "optimizer = optim.Adam(downstream_model.parameters(), lr=0.001)\n",
        "\n",
        "run_training(downstream_model, svhn_trainloader, svhn_testloader, criterion = criterion, optimizer = optimizer, num_epochs = epochs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyP9MuXEi1ExilIlgLa40zMJ",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
